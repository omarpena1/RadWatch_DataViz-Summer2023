{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPBwrxq8h-WO"
   },
   "source": [
    "'''\n",
    "Homework:\n",
    "\n",
    "Look back at the notebook you submitted during your application, and reimplement your solution here.\n",
    "\n",
    "Now, it's time to edit your code! Please try to utilize the code that's already written to complete this assignment.\n",
    "\n",
    "Then,\n",
    "* Instead of sourcing every file, I want you to only source uw_weather.csv\n",
    "https://dl.dropboxusercontent.com/s/wrfnznthlg8mo1j/uw_weather.csv?dl=1\n",
    "\n",
    "* Calculate the mean of the temperatures over a specific time period. \n",
    "Namely,from the datapoint\n",
    "\n",
    "from the datapoint:\n",
    "2023-02-01 00:01:34+0000,2023-01-31 16:01:34-0800,1675209694.22,13.47,1016.23,34.58,0\n",
    "to the datapoint\n",
    "2023-02-05 00:01:34+0000,2023-02-04 16:01:34-0800,1675555294.22,17.73,1006.12,52.26,0\n",
    "\n",
    "Do not worry about inconsistencies, skipped days, etc. Simply add up all the temperature measurements available over the time period, and divide it by the number of measurements.\n",
    "\n",
    "* Then, I want you to graph this location in a histogram using Plotly.\n",
    "- Title the plot: 'UW Mean Temperature 02/01 - 02/05 \n",
    "- Name the x-axis: Locations\n",
    "- Name the y-axis: Temperature\n",
    "\n",
    "* After completing the previous steps, use the DataFrame of the data to create a line chart using Plotly\n",
    "    - Calculate the mean for every day within the timeframe of 02-01 and 02-04 in deviceTime_utc.\n",
    "    - One day is the first entry of the date to last entry of the date in UTC. \n",
    "    (i.e. \n",
    "    From 2023-02-01 00:01:34+0000,2023-01-31 16:01:34-0800,1675209694.22,13.47,1016.23,34.58,0\n",
    "    To 2023-02-01 23:56:34+0000,2023-02-01 15:56:34-0800,1675295794.22,17.16,1013.9,32.21,0\n",
    "    \n",
    "Again, do not worry about inconsistencies, just calculate the mean using the available measurements and the # of measurements. \n",
    "    - The x-axis should be the dates of the selected days\n",
    "    - The y-axis should be mean temperature\n",
    "    \n",
    "If anything is unclear, ask Vikram!\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "a8MdthKx1J3A"
   },
   "outputs": [],
   "source": [
    "#@title IGNORE\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8q3u3Hj8v0v"
   },
   "outputs": [],
   "source": [
    "#@title [GIVEN] Step 1. Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import requests\n",
    "from io import StringIO\n",
    "import plotly.express as px\n",
    "\n",
    "url=\"https://radwatch.berkeley.edu/test/tmp/Station.csv\"\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "s=requests.get(url, headers=header).text\n",
    "stations=pd.read_csv(StringIO(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Be7K8bW71ui_"
   },
   "outputs": [],
   "source": [
    "#@title [GIVEN] Step 2. Import list of stations (Station.csv) and convert into DataFrame\n",
    "#filePath=\"/Station.csv\"\n",
    "# This is the file path from which the CSV file containing the data is sourced.\n",
    "#stations=pd.read_csv(filePath)\n",
    "#This CSV file is sent to Pandas' (pd) read_csv method.\n",
    "#The read_csv method saves converts CSV file as a Pandas Dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNrrhteu09Hk"
   },
   "outputs": [],
   "source": [
    "#@title [GIVEN] Station data file function\n",
    "\n",
    "def grabFile(nickname=\"\"):\n",
    "    try:\n",
    "      url=\"https://radwatch.berkeley.edu/test/tmp/dosenet/\" + nickname + \"_aq_month.csv\" #nickname is used in URL to source CSV file for location.\n",
    "      locationCSV =requests.get(url, headers=header).text #grabs the CSV file for location\n",
    "      locationDF =pd.read_csv(StringIO(locationCSV)) #reads the CSV file into Pandas Dataframe.\n",
    "    except: #if necessary tasks result in an error, the location is skipped\n",
    "        print('FILE NOT FOUND!')\n",
    "        raise Exception(\"Error Occured [Skipped]\")\n",
    "    else: #if the tasks were successful, it will do the following\n",
    "        return locationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyAd9o3khjfE",
    "outputId": "c674be11-6ab4-4c45-9b04-0b88c9988441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE NOT FOUND!\n",
      "error occured, df for lbl [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for campolindo [skipped]\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for etch [skipped]\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for koriyama_ch [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for foothills [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for jlhs [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for ebia [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for kaist [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for alameda_hs [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for harbor_bay [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for dshs [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for life_academy [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for KTH [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for norrareal [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for ghs [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for miramonte [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for JAEA_ms [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for hillside_high [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for frankfurt [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for hf6 [skipped]\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for ntuu_kpi [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for cnut [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for cherkasy [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for sabacka [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for lbl_outside [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for fukushimahs [skipped]\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for ahs_os [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for kisr-1 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for futabahighschool [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for futabafutureschool [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for asakahighschool [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for hiroshima [skipped]\n",
      "done.\n",
      "done.\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for fphs [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for fphs_os [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for msjhs [skipped]\n",
      "done.\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for tyler [skipped]\n",
      "done.\n",
      "done.\n",
      "done.\n",
      "done.\n",
      "FILE NOT FOUND!\n",
      "error occured, df for themba [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for denver_home [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for schs_wv [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test1 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test2 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test3 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test4 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test5 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test6 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test7 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test8 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test9 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test10 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test_brian [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test_tyler [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test20001 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test20002 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for test20003 [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for cssc [skipped]\n",
      "FILE NOT FOUND!\n",
      "error occured, df for grabow [skipped]\n",
      "\n",
      "\n",
      "** complete. **\n",
      "               deviceTime_utc           deviceTime_local  deviceTime_unix  \\\n",
      "0   2019-01-29 08:16:11+00:00  2019-01-29 00:16:11-08:00     1.548750e+09   \n",
      "1   2019-01-29 01:11:16+00:00  2019-01-28 17:11:16-08:00     1.548724e+09   \n",
      "2   2019-01-28 21:21:16+00:00  2019-01-28 13:21:16-08:00     1.548710e+09   \n",
      "3   2019-01-28 17:21:17+00:00  2019-01-28 09:21:17-08:00     1.548696e+09   \n",
      "4   2019-01-28 13:21:17+00:00  2019-01-28 05:21:17-08:00     1.548682e+09   \n",
      "..                        ...                        ...              ...   \n",
      "61  2019-01-03 12:21:59+00:00  2019-01-03 04:21:59-08:00     1.546518e+09   \n",
      "62  2019-01-03 09:21:59+00:00  2019-01-03 01:21:59-08:00     1.546507e+09   \n",
      "63  2019-01-03 05:22:05+00:00  2019-01-02 21:22:05-08:00     1.546493e+09   \n",
      "64  2019-01-03 01:22:05+00:00  2019-01-02 17:22:05-08:00     1.546479e+09   \n",
      "65  2019-01-02 21:22:04+00:00  2019-01-02 13:22:04-08:00     1.546464e+09   \n",
      "\n",
      "         PM1      PM25       PM10  \n",
      "0   2.992000  4.642000   5.580000  \n",
      "1   6.017500  8.059318   9.227500  \n",
      "2   4.271458  6.255625   7.308333  \n",
      "3   6.238542  8.752083  10.298958  \n",
      "4   2.639792  4.436458   5.236042  \n",
      "..       ...       ...        ...  \n",
      "61  0.987308  2.285385   3.009615  \n",
      "62  1.528571  2.831224   3.677959  \n",
      "63  0.733542  1.487708   1.806458  \n",
      "64  0.000000  0.006458   0.006875  \n",
      "65  0.077708  0.399375   0.533750  \n",
      "\n",
      "[66 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#@title Step 3. Grab all the station names and monthly data files. Save them as lists.\n",
    "#Write your code here.\n",
    "stationDFs = [] #this variable will be used to store Pandas Dataframes for each station.\n",
    "areaNames = [] #this variable will be used to store the names of each station.\n",
    "\n",
    "for areas in range(1,len(stations.index)): #loop over the length of (# of locations in) the DataFrame\n",
    "    try: #this attemps to complete necessary tasks for the location\n",
    "        nickname = stations['nickname'][areas] #grab nickname from the 'nickname' column for location.\n",
    "        name = stations['Name'][areas] #grabs the full name of the location\n",
    "        locationDF = grabFile(nickname)\n",
    "    except: #if necessary tasks result in an error, the location is skipped\n",
    "        print('error occured, df for ' + nickname + ' [skipped]')\n",
    "        continue\n",
    "    else: #if the tasks were successful, it will do the following\n",
    "        stationDFs.append(locationDF) #add dataframe to list\n",
    "        areaNames.append(name) #add full name of the location to list\n",
    "        print('done.')\n",
    "print('\\n\\n** complete. **')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-l5TC4KwqsOz",
    "outputId": "ae45fed7-6de5-4b93-f252-9233d3b5348f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               deviceTime_utc           deviceTime_local  deviceTime_unix  \\\n",
      "0   2019-01-29 08:16:11+00:00  2019-01-29 00:16:11-08:00     1.548750e+09   \n",
      "1   2019-01-29 01:11:16+00:00  2019-01-28 17:11:16-08:00     1.548724e+09   \n",
      "2   2019-01-28 21:21:16+00:00  2019-01-28 13:21:16-08:00     1.548710e+09   \n",
      "3   2019-01-28 17:21:17+00:00  2019-01-28 09:21:17-08:00     1.548696e+09   \n",
      "4   2019-01-28 13:21:17+00:00  2019-01-28 05:21:17-08:00     1.548682e+09   \n",
      "..                        ...                        ...              ...   \n",
      "61  2019-01-03 12:21:59+00:00  2019-01-03 04:21:59-08:00     1.546518e+09   \n",
      "62  2019-01-03 09:21:59+00:00  2019-01-03 01:21:59-08:00     1.546507e+09   \n",
      "63  2019-01-03 05:22:05+00:00  2019-01-02 21:22:05-08:00     1.546493e+09   \n",
      "64  2019-01-03 01:22:05+00:00  2019-01-02 17:22:05-08:00     1.546479e+09   \n",
      "65  2019-01-02 21:22:04+00:00  2019-01-02 13:22:04-08:00     1.546464e+09   \n",
      "\n",
      "         PM1      PM25       PM10  \n",
      "0   2.992000  4.642000   5.580000  \n",
      "1   6.017500  8.059318   9.227500  \n",
      "2   4.271458  6.255625   7.308333  \n",
      "3   6.238542  8.752083  10.298958  \n",
      "4   2.639792  4.436458   5.236042  \n",
      "..       ...       ...        ...  \n",
      "61  0.987308  2.285385   3.009615  \n",
      "62  1.528571  2.831224   3.677959  \n",
      "63  0.733542  1.487708   1.806458  \n",
      "64  0.000000  0.006458   0.006875  \n",
      "65  0.077708  0.399375   0.533750  \n",
      "\n",
      "[66 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(stationDFs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ISaKJkV8hjk4"
   },
   "outputs": [],
   "source": [
    "#@title Step 4. Calculate means for each station's data. Save them as lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ekQpiPInh5FR"
   },
   "outputs": [],
   "source": [
    "#@title Step 5. Create a DataFrame consisting of error, mean (average), and sesnor names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "VlgJ2oPp2TT9"
   },
   "outputs": [],
   "source": [
    "#@title Step 6. Generate a Bar Chart figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWuxdsmL2jxd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
