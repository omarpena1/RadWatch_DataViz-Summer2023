{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d92b0-c1dc-4d02-a7bc-190677055508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import math\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b407673a-c389-4088-bede-2d59bc78ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "uw = pd.read_csv(r'C:\\Users\\pomar\\Downloads\\uw_weather.csv')\n",
    "etch_roof = pd.read_csv(r'C:\\Users\\pomar\\Downloads\\etch_roof_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cf97b-c559-480e-8dff-a8911b2a4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(uw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbd45f-351f-48e7-97d1-79fdc74dfcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uw.columns.get_loc(\"2023-02-01 00:01:34+0000\")\n",
    "print(np.where(uw[\"deviceTime_utc\"]==\"2023-02-01 00:01:34+0000\"))\n",
    "print(np.where(uw[\"deviceTime_utc\"]==\"2023-02-05 00:01:34+0000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fac026-c681-4e8f-b1ab-89562e7b8901",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_splice = uw.loc[212346:213498,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7254c61-7ef3-40c2-b8d3-2a1402e14767",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(our_splice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf092fd-3816-4146-a9aa-cb3e9609ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(our_splice[\"deviceTime_utc\"][212347])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f24a75d-2c80-4932-850e-763336e63812",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_temp_splice = (uw[\"temperature\"].sum())/(len(uw[\"temperature\"]))\n",
    "print(mean_temp_splice)\n",
    "display(our_splice[\"deviceTime_utc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1695484-bd0f-4394-80c4-dfff16ef9bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_splice = px.data.tips()\n",
    "# fig = px.histogram(our_splice, x=uw[\"deviceTime_local\"], y=uw[\"temperature\"])\n",
    "# update_layout(xaxis_title=\"Time\", yaxis_title=\"Temperature\")\n",
    "# fig = px.histogram(our_splice, x=our_splice[\"deviceTime_utc\"], y=our_splice[\"temperature\"])\n",
    "fig = px.histogram(our_splice, x=our_splice[\"temperature\"])\n",
    "fig.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\" )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdea9aa6-88f5-4fe5-9a82-ba3fa6b84a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(our_splice, x=our_splice[\"deviceTime_utc\"])\n",
    "fig.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"UTC\",yaxis_title=\"Frequency\" )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bcb8b-c278-420a-9521-478cb2433e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired = []\n",
    "save = []\n",
    "days = [\"2023-02-01\",\"2023-02-02\",\"2023-02-03\",\"2023-02-04\"]\n",
    "counter = 0\n",
    "for i in range(212346,213499):\n",
    "    if days[counter] in our_splice[\"deviceTime_utc\"][i]:\n",
    "        save.append(our_splice[\"temperature\"][i])\n",
    "    else:\n",
    "        meantemp = sum(save)/len(save)\n",
    "        desired.append(meantemp)\n",
    "        save = []\n",
    "        counter = counter + 1\n",
    "\n",
    "print(desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816f93b-63ef-4867-8c62-fbe993a3a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=[\"Feb 1, 2023\",\"Feb 2, 2023\",\"Feb 3,2023\", \"Feb 4, 2023\"], y=desired)\n",
    "fig.update_layout(title=\"UW Mean Temperature 02/01 - 02/04\",xaxis_title=\"Date\",yaxis_title=\"Temperature °C\" )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b50d78-19c3-4554-b6ef-ac491a20ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(etch_roof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b1f00-c4bc-4a17-a702-739e4b4d812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.histogram(etch_roof, x=etch_roof[\"temperature\"], color = 'error_flag')\n",
    "fig2.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode=\"overlay\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d78e3d-dec3-4937-a07e-2f59afb3f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.histogram(etch_roof, x=etch_roof[\"temperature\"])\n",
    "fig2.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode=\"overlay\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae39792-d3b2-4672-be83-28cb04957f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whole data Histograms\n",
    "\n",
    "fig = px.histogram(uw, x=uw[\"temperature\"])\n",
    "fig.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode=\"overlay\")\n",
    "fig2 = px.histogram(etch_roof, x=etch_roof[\"temperature\"])\n",
    "fig2.update_layout(title=\"UW Temperature 02/01 - 02/05\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode=\"overlay\")\n",
    "fig.show()\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb7901-f464-43ce-9c66-f0216dda00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_uw = []\n",
    "for i in range(len(uw)):\n",
    "    indicator_uw.append(\"UW Data\")\n",
    "\n",
    "# indicator_dic_uw = [\"indicator\" : indicator_uw]\n",
    "\n",
    "uw2 = uw.assign(indicator=indicator_uw)\n",
    "\n",
    "indicator_etch = []\n",
    "for i in range(len(etch_roof)):\n",
    "    indicator_etch.append(\"Etcheverry Roof Data\")\n",
    "\n",
    "etch_roof2 = etch_roof.assign(indicator=indicator_etch)\n",
    "\n",
    "prelim = [uw2, etch_roof2]\n",
    "concatenated = pd.concat(prelim)\n",
    "display(concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee6a174-9ee3-4c7d-acc5-f29d9d4fd3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e6d91-15e7-4fa7-a369-f2e5293af6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = px.histogram(concatenated, x=concatenated[\"temperature\"], color = 'indicator')\n",
    "fig2.update_layout(title=\"UW and Etcheverry Roof Temperature Total Data Comparison Test\",xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode=\"overlay\")\n",
    "fig2.update_traces(opacity=0.75)\n",
    "fig2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6152ce-5ad6-416f-a915-b5b3be359288",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=etch_roof[\"temperature\"], name = \"Etcheverry Roof\"))\n",
    "fig.add_trace(go.Histogram(x=uw[\"temperature\"], name = \"UW\", nbinsx = 500))\n",
    "fig.update_layout(title=\"UW and Etcheverry Roof Temperature Total Data Comparison Test\", xaxis_title=\"Temperature °C\",yaxis_title=\"Frequency\", barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f1afe-5df5-4af8-bdd4-4ee68a5dcb97",
   "metadata": {},
   "source": [
    "Find a way to find the average weekly temperature for a location given a date and considering the week before this date\n",
    "604800 seconds in a week \n",
    "subtract that from the unix time given, and find in that same data frame, the closest index to the unix time subtracted from the 604800 seconds in a week.\n",
    "df.tail(nth_row_index).index[column_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ca9a0-ee09-4449-8923-2d0fbbd68d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splice = uw.iloc[6:12,2:]\n",
    "display(splice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dafc6dc-543f-4b14-9005-c0ab6adc82d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_week_back(dataframe):\n",
    "    endUnix = dataframe[\"deviceTime_unix\"][(len(dataframe)-1)]\n",
    "    idealstartUnix = endUnix - 604800\n",
    "    for i in range(len(dataframe)):\n",
    "        if(dataframe[\"deviceTime_unix\"][i]>=idealstartUnix):\n",
    "            closestfit = i\n",
    "            break\n",
    "    return closestfit\n",
    "\n",
    "# def weekly_ave(dataframe, start):\n",
    "#     splice = dataframe.iloc[start:len(dataframe),:]\n",
    "#     weekly_ave = splice[\"temperature\"].sum()/(len(dataframe))\n",
    "#     return weekly_ave\n",
    "\n",
    "def weekly_ave(dataframe):\n",
    "    splice = dataframe.iloc[(len(dataframe)-7):len(dataframe),:]\n",
    "    weekly_ave = splice[\"temperature\"].sum()/(len(splice)) \n",
    "    return weekly_ave\n",
    "\n",
    "#locations and location_dfs are both lists\n",
    "def create_bar_df(locations,location_dfs):\n",
    "    weekly_temperature = []\n",
    "    for x in range(len(location_dfs)):\n",
    "        weekly_temperature.append(weekly_ave(location_dfs[x]))\n",
    "    df_data = {\"locations\" : locations, \"weekly_temp\" : weekly_temperature}\n",
    "    final_df = pd.DataFrame(df_data)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da9175-8825-4c89-9817-f024466558d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_week_back(dataframe):\n",
    "    endUnix = dataframe[\"deviceTime_unix\"][(len(dataframe)-1)]\n",
    "    idealstartUnix = endUnix - 604800\n",
    "    for i in range(len(dataframe)):\n",
    "        if(dataframe[\"deviceTime_unix\"][i]>=idealstartUnix):\n",
    "            closestfit = i\n",
    "            break\n",
    "    return closestfit\n",
    "\n",
    "# def weekly_ave(dataframe, start):\n",
    "#     splice = dataframe.iloc[start:len(dataframe),:]\n",
    "#     weekly_ave = splice[\"temperature\"].sum()/(len(dataframe))\n",
    "#     return weekly_ave\n",
    "\n",
    "def weekly_ave(dataframe):\n",
    "    splice = dataframe.iloc[(a_week_back(dataframe)):len(dataframe),:]\n",
    "    weekly_ave = splice[\"temperature\"].sum()/(len(splice)) \n",
    "    return weekly_ave\n",
    "\n",
    "#locations and location_dfs are both lists\n",
    "def create_bar_df(locations,location_dfs):\n",
    "    weekly_temperature = []\n",
    "    for x in range(len(location_dfs)):\n",
    "        weekly_temperature.append(weekly_ave(location_dfs[x]))\n",
    "    df_data = {\"locations\" : locations, \"weekly_temp\" : weekly_temperature}\n",
    "    final_df = pd.DataFrame(df_data)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9fa36-2f84-46c5-bf12-13192bbafc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(uw)\n",
    "\n",
    "# # print(weekly_ave(uw,0,216818))\n",
    "# # print(weekly_ave(uw,0,216819))\n",
    "# # print(uw.sum())\n",
    "# print(weekly_ave(uw))\n",
    "# print(uw[\"temperature\"].mean())\n",
    "\n",
    "sample_locs = [\"UW\",\"Etcheverry Roof\"]\n",
    "sample_df_list = [uw, etch_roof]\n",
    "\n",
    "#with grab[] function you will get a location list and a df list with the data\n",
    "\n",
    "display(create_bar_df(sample_locs, sample_df_list))\n",
    "\n",
    "sample = create_bar_df(sample_locs, sample_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a19e4-4f7a-4d91-a84b-55d474fa2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"crimson\",\"lightslategray\"]\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(\n",
    "    x=sample[\"locations\"],\n",
    "    y=sample[\"weekly_temp\"],\n",
    "    marker_color=colors # marker color can be a single color value or an iterable\n",
    ")])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156518d-9c44-4bf7-ba67-c03da2304179",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(sample, x=sample[\"locations\"], y = sample[\"weekly_temp\"], title=\"Weekly temperature averages at different locations\", labels=dict(locations=\"Locations\", weekly_temp=\"Average Weekly Temperature\"),\n",
    "             color = \"locations\")\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c681c-3142-431e-8c19-5e6bc27121ff",
   "metadata": {},
   "source": [
    "Sort of Part 2 of this project, we will use the grabFile command to access csv's from the internet instead of directly downloading the weather data onto our pc. Make it so that bar charts are generated from the average weekly temperature of all the stations using the functions I've defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172f5db-511c-463b-8f8f-fcfbd61baab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title IGNORE\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2bf70-2a60-464c-b0d6-90804e586ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://radwatch.berkeley.edu/test/tmp/Station.csv\"\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "s=requests.get(url, headers=header).text\n",
    "stations=pd.read_csv(StringIO(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491a933-58c5-4497-862d-f2ed94baa449",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [GIVEN] Step 2. Import list of stations (Station.csv) and convert into DataFrame\n",
    "#filePath=\"/Station.csv\"\n",
    "# This is the file path from which the CSV file containing the data is sourced.\n",
    "#stations=pd.read_csv(filePath)\n",
    "#This CSV file is sent to Pandas' (pd) read_csv method.\n",
    "#The read_csv method saves converts CSV file as a Pandas Dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ac2ea-c15a-408f-a540-a048166df792",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv(r'C:\\Users\\pomar\\Downloads\\Station.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb4d20-df5a-4718-89c8-5037a25c2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title [GIVEN] Station data file function\n",
    "import listofstations\n",
    "def grabFile(nickname=\"\"):\n",
    "    try:\n",
    "      url=listofstations.stationsdict[nickname] #nickname is used in URL to source CSV file for location.\n",
    "      locationCSV =requests.get(url, headers=header).text #grabs the CSV file for location\n",
    "      locationDF =pd.read_csv(StringIO(locationCSV)) #reads the CSV file into Pandas Dataframe.\n",
    "    except: #if necessary tasks result in an error, the location is skipped\n",
    "        print('FILE NOT FOUND!')\n",
    "        raise Exception(\"Error Occured [Skipped]\")\n",
    "    else: #if the tasks were successful, it will do the following\n",
    "        return locationDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a96ed0-22cf-4af0-802c-2b819852e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "grabFile(\"etch_roof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e772f8b-f4c6-4daa-8cb8-548ef016daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Step 3. Grab all the station names and monthly data files. Save them as lists.\n",
    "#Write your code here.\n",
    "stationDFs = [] #this variable will be used to store Pandas Dataframes for each station.\n",
    "areaNames = [] #this variable will be used to store the names of each station.\n",
    "\n",
    "for areas in range(1,len(stations.index)): #loop over the length of (# of locations in) the DataFrame\n",
    "    try: #this attemps to complete necessary tasks for the location\n",
    "        nickname = stations['nickname'][areas] #grab nickname from the 'nickname' column for location.\n",
    "        name = stations['Name'][areas] #grabs the full name of the location\n",
    "        locationDF = grabFile(nickname)\n",
    "    except: #if necessary tasks result in an error, the location is skipped\n",
    "        print('error occured, df for ' + nickname + ' [skipped]')\n",
    "        continue\n",
    "    else: #if the tasks were successful, it will do the following\n",
    "        stationDFs.append(locationDF) #add dataframe to list\n",
    "        areaNames.append(name) #add full name of the location to list\n",
    "        print('done.' + nickname)\n",
    "print('\\n\\n** complete. **')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312b08d-96ad-44a0-9f73-a5609ca22454",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(areaNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e344d7-43cc-4d84-85e5-e6464266caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stationDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ffcfac-ce51-4486-991f-25712f309dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stationDFs[0]) #From our areaNames df we determine that this df in stationDFs corresponds to Pinewood School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50c980-e7d9-4a44-ab3a-a6aebbc68325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_week_back(dataframe):\n",
    "    endUnix = dataframe[\"deviceTime_unix\"][(len(dataframe)-1)]\n",
    "    idealstartUnix = endUnix - 604800\n",
    "    for i in range(len(dataframe)):\n",
    "        if(dataframe[\"deviceTime_unix\"][i]>=idealstartUnix):\n",
    "            closestfit = i\n",
    "            break\n",
    "    return closestfit\n",
    "\n",
    "def weekly_ave(dataframe, sumover):\n",
    "    splice = dataframe.iloc[(a_week_back(dataframe)):len(dataframe),:]\n",
    "    weekly_ave = splice[sumover].sum()/(len(splice)) \n",
    "    return weekly_ave\n",
    "\n",
    "#locations and location_dfs are both lists\n",
    "def create_bar_df(locations,location_dfs,sumover):\n",
    "    weeklyave = []\n",
    "    for x in range(len(location_dfs)):\n",
    "        weeklyave.append(weekly_ave(location_dfs[x],sumover))\n",
    "    df_data = {\"locations\" : locations, sumover + \"_ave\" : weeklyave}\n",
    "    final_df = pd.DataFrame(df_data)\n",
    "    return final_df\n",
    "\n",
    "goal = create_bar_df(areaNames, stationDFs, \"cpm\")\n",
    "display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed97b4f-665c-4d02-b6a4-8728a088bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# color = px.colors.qualitative.Plotly\n",
    "# goal = goal.iloc[:,:]\n",
    "\n",
    "fig = px.bar(goal, x=goal[\"locations\"], y = goal[\"cpm_ave\"], title=\"Weekly CPM averages at different locations\", labels=dict(x=\"Locations\", y=\"Average Weekly CPM\", color = \"Locations\"),\n",
    "             color = goal[\"locations\"])\n",
    "\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832e834-70cd-449b-b190-7f2b476f38d7",
   "metadata": {},
   "source": [
    "So now, lets review the steps needed to produce a plot with the above functions. We have a_week_back(dataframe) which will return the index that is a week behind the last entry in the dataframe. If there is no exact match between the time stamp that is exactly a week behind the last index, the function will return the closest index that is a week behind the latest entry. As such, in the case of dataframes that were sampled for less than a week, a_week_back() will just return the first index.\n",
    "\n",
    "the weekly_ave(dataframe, sumover) will call a_week_back() and splice the argument dataframe from the index produced by a_week_back() to the latest entry. weekly_ave() will then sum over the variable specified by string sumover on the spliced dataframe and divide by the length of the spliced dataframe to get and return the weekly mean for the variable sumover.\n",
    "\n",
    "grab_File(nickaname) accesses csv's from the internet to be used within the notebook without having to download them onto your PC. The subsequent loops that populate stationDFs and areaNames use grab_File() to attempt and access the csv for each station on the nickname column of Stations.csv, which is predownloaded and has to be manually read into a dataframe, (NOT TRUE it doesnt have to be predownloaded). The loops check to see if the csv is able to be accessed, and if succesful, adds the name of the locations from this csv to areaNames and adds their dataframe to stationDFs. The result is two index-for-index lists of locations and the data collected at these locations as dataframes. areaNames should be input as the locations argument and stationDFs as the location_dfs argument in create_bar_df().\n",
    "\n",
    "grab_File(nickname)  accesses csv's from the internet to be used within the notebook without having to download them onto your PC. The subsequent loops that populate stationDFs and areaNames use grab_File() to attempt and access the csv for each station from a predownlaoded dictionary contained in listofstations.py\n",
    "\n",
    "the create_bar_df(locations, location_dfs, sumover) function will loop through location_dfs, which is a list of dataframes. At each dataframe within locations_dfs, the function will call weekly_ave(dataframe, sumover) and populate a list with the weekly averages of variable sumover. From the list locations, which is a list of locations that corresponds index for index to the list of weekly averages, a final dataframe is returned with two columns, one listing the locations and the other the corresponding weekly averages of some variable at those locations. \n",
    "\n",
    "The dataframe from create_bar_df() can then easily be formatted by plotly express to produce our desired bar graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc42a16-31ef-4664-a027-695cd8d836b8",
   "metadata": {},
   "source": [
    "So the final code that could be used for the project could:\n",
    "\n",
    "1. Manually import Stations.csv in a df import listofstations.py\n",
    "2. define grabFile() function\n",
    "3. define areaNames and stationDFs\n",
    "4. Loop over the nickname column of Stations.csv, using grabFile() to fill areaNames and stationDFs with info from all accessible stations\n",
    "5. define a_week_back(), weekly_ave(), and create_bar_df()\n",
    "6. call create_bar_df() with areaNames, stationDFs, and the variable we want to display on the final bar graph\n",
    "7. Format the create_bar_df dataframe with plotly express to produce a final graph that can be exported to HTML and displayed on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a646fa-eb36-492f-a994-de524b50f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly.io.to_html(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe133e-ada2-45e3-ad60-8605e5c8d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.plot(fig, filename=r'C:\\Users\\pomar\\Downloads\\plotlycpmgraph.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f5de5a-5888-4378-b852-f4ac68fd09d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
